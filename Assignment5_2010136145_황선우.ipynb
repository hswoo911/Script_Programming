{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5 \n",
    "# 2010136145 황선우\n",
    "\n",
    "## 1. 문제 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1번 문제] 클래스와 모듈의 공통점과 차이점에 대해 설명하시오.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 공통점: 클래스와 모듈 모두 독립적 이름공간을 제공해주는 대표적인 단위이며 독립적인 구성요소로 활용되기때문에 프로그램을 모듈화 한다.\n",
    " - 차이점: 모듈은 파일 단위로 이름 공간을 구성하는 반면 클래스는 클래스 영역 내에 이름 공간을 구성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2번 문제] 다형성에 대해 설명하고 다형성을 보여주는 자신만의 파이썬 코드 예제를 제시하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상속 관계 내의 다른 클래스들의 인스턴스들이 같은 멤버 함수 호출에 대해 각각 다르게 반응 하도록 하는 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just Spoon\n",
      "흙수저\n",
      "금수저\n",
      "다이아수저\n"
     ]
    }
   ],
   "source": [
    "class Spoon:\n",
    "    def check(self):\n",
    "        print 'Just Spoon'\n",
    "class SoilSpoon(Spoon):\n",
    "    def check(self):\n",
    "        print '흙수저'\n",
    "class GoldSpoon(Spoon):\n",
    "    def check(self):\n",
    "        print '금수저'\n",
    "class DiamondSpoon(Spoon):\n",
    "    def check(self):\n",
    "        print '다이아수저'\n",
    "\n",
    "for spoon in (Spoon(), SoilSpoon(), GoldSpoon(), DiamondSpoon()):\n",
    "    spoon.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3번 문제] 다음 각 요구사항 모두를 만족시키는 Counter 클래스를 코딩하시오 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Count (step: 1)] 11\n",
      "[Count (step: 2)] 12\n",
      "[Count (step: 1)] 12\n",
      "[Count (step: 2)] 14\n",
      "[Count (step: 1)] 17\n",
      "[Count (step: 2)] 9\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "class Counter:\n",
    "    def __init__(self, count = None, step = 1):\n",
    "        self.count = count\n",
    "        self.step = step\n",
    "    def __str__(self):\n",
    "        return '[Count (step: %d)] %d'%(self.step, self.count)\n",
    "    def incr(self):\n",
    "        self.count += self.step\n",
    "    def __call__(self):\n",
    "        self.incr()\n",
    "    def __add__(self, other):\n",
    "        return Counter(self.count + other, self.step)\n",
    "    def __sub__(self, other):\n",
    "        return Counter(self.count - other, self.step)\n",
    "    def __gt__(self, other):\n",
    "        return self.count > other\n",
    "    def __lt__(self, other):\n",
    "        return self.count < other\n",
    "    def __eq__(self, other):\n",
    "        return self.count == other\n",
    "    def __ne__(self, other):\n",
    "        return self.count != other\n",
    "\n",
    "\n",
    "c = Counter(10) \n",
    "d = Counter(10, 2)\n",
    "c.incr()\n",
    "d.incr()\n",
    "print c\n",
    "print d\n",
    "c()\n",
    "d()\n",
    "print c\n",
    "print d\n",
    "c = c + 5\n",
    "d = d - 5\n",
    "print c\n",
    "print d\n",
    "print c > 10\n",
    "print d > 10\n",
    "print c < 10\n",
    "print d < 10\n",
    "print c == 17\n",
    "print d != 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4번 문제]\n",
    "\n",
    "다음은 내장 자료형 list를 서브클래싱하여 만든 MySet 클래스 정의 내용이다. 다음 클래스 정의에서 \\_\\_init\\_\\_(), \\_\\_str()\\_\\_(), elimicate_duplicate()의 세 개의 메소드 코드 내용을 자신이 다른 사람에게 가르친다고 생각하며 설명해보시오.\n",
    " - MySet은 집합(Set) 자료형을 정의하려는 의도하에 만들어진 클래스이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySet: {1 ,2 ,3}\n",
      "MySet: {2 ,3 ,4 ,5 ,6 ,7 ,8 ,9}\n"
     ]
    }
   ],
   "source": [
    "class MySet(list):\n",
    "    def __init__(self, l):\n",
    "        for e in l:\n",
    "            self.append(e)\n",
    "        MySet.eliminate_duplicate(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        result = \"MySet: {\"\n",
    "        for e in self:\n",
    "            result = result + str(e) + \" ,\"\n",
    "        result = result[0:len(result)-2] + \"}\"\n",
    "        return result\n",
    "\n",
    "    @staticmethod    \n",
    "    def eliminate_duplicate(l):\n",
    "        s = []\n",
    "        for e in l:\n",
    "            if e not in s:\n",
    "                s.append(e)\n",
    "        l[:] = []\n",
    "        for e in s:\n",
    "            l.append(e)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    s = MySet([1, 2, 2, 3])\n",
    "    print s\n",
    "    t = MySet([2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 8, 9])\n",
    "    print t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - \\_\\_init\\_\\_(): \\_\\_init\\_\\_()은 Myset의 생성자로써 인스턴스 생성시 호출되며 하나의 인자로 리스트를 받는다. 인자로 받은 리스트의 원소를 하나씩 꺼내 자기 자신에게 append시키는데 이 때 append메소드는 Myset에 존재하지 않고 슈퍼클래스인 list에 있는 append 메소드이다. l의 원소를 모두 append한 후 정적 메소드인 eliminate_duplicate를 호출한다.\n",
    " - \\_\\_str()\\_\\_(): 객체를 print했을 때 불리는 메소드이다. result라는 문자열 변수를 MySet: {1 ,2 ,3} 이러한 형식으로 만들어 리턴한다.\n",
    " - elimicate_duplicate(): elimicate_duplicate()는 정적 메소드로서 인스턴스 객체와 무관하게 클래스 이름 공간에 존재하는 메소드이다. 따라서 클래스 이름을 이용하여 직접 호출할 수 있다. 인자로 리스트 하나를 받아 임시 리스트인 s에 리스트의 원소를 중복없이 저장한 후 전달 받은 리스트를 비우고 s의 원소를 채운다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5번 문제]\n",
    "\n",
    "4번 문제에 정의된 MySet 클래스에 메소드를 추가하여 다음 각 요구사항 모두를 만족시키는 코딩을 제시하시오\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySet: {1 ,2 ,3}\n",
      "MySet: {2 ,3 ,4 ,5 ,6 ,7 ,8 ,9}\n",
      "MySet: {1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9}\n",
      "MySet: {2 ,3}\n",
      "MySet: {1 ,2}\n"
     ]
    }
   ],
   "source": [
    "class MySet(list):\n",
    "    def __init__(self, l):\n",
    "        for e in l:\n",
    "            self.append(e)\n",
    "        MySet.eliminate_duplicate(self)\n",
    "    \n",
    "    def __str__(self):\n",
    "        result = \"MySet: {\"\n",
    "        for e in self:\n",
    "            result = result + str(e) + \" ,\"\n",
    "        result = result[0:len(result)-2] + \"}\"\n",
    "        return result\n",
    "    def __or__(self, other):\n",
    "        result = self + other\n",
    "        MySet.eliminate_duplicate(result)\n",
    "        return MySet(result)\n",
    "    def __and__(self, other):\n",
    "        result = []\n",
    "        for e in self:\n",
    "            if e in other:\n",
    "                result.append(e)\n",
    "        return MySet(result)\n",
    "    def __sub__(self, other):\n",
    "        i = 0\n",
    "        while i != len(self):\n",
    "            if self[i] in other:\n",
    "                del(self[i])\n",
    "            else:\n",
    "                i += 1\n",
    "        return MySet(self)\n",
    "\n",
    "\n",
    "    @staticmethod    \n",
    "    def eliminate_duplicate(l):\n",
    "        s = []\n",
    "        for e in l:\n",
    "            if e not in s:\n",
    "                s.append(e)\n",
    "        l[:] = []\n",
    "        for e in s:\n",
    "            l.append(e)\n",
    "\n",
    "s = MySet([1, 2, 2, 3])\n",
    "print s\n",
    "t = MySet([2, 3, 4, 5, 6, 7, 8, 8, 8, 8, 8, 9])\n",
    "print t\n",
    "\n",
    "u = s | t\n",
    "print u\n",
    "u = s & t \n",
    "print u\n",
    "\n",
    "s = MySet([1, 2, 3]) \n",
    "t = MySet([3, 4, 5]) \n",
    "u = s - t \n",
    "print u "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [6번 문제]\n",
    "\n",
    "5번 문제에서 정의한 MySet 클래스에 대해 다음 예제를 수행하면 오류없이 올바르게 동작하는 것을 확인할 수 있다. 다음 예제 내에 있는 len(), bool() 내장함수와 in 키워드 사용 예제가 별다른 메소드 정의를 하지 않았는 데도 올바르게 수행되는 이유를 설명하시오.\n",
    "\n",
    ">\\>\\>\\> s = MySet([1, 2, 3, 4, 5, 6])  \n",
    "\\>\\>\\> print len(s)  \n",
    "\\> 6  \n",
    "\\>\\>\\> print bool(s)  \n",
    "\\> True  \n",
    "\\>\\>\\> print 2 in s  \n",
    "\\> True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MySet에 없는 메소드인 len(), bool(), in키워드는 호출 시 MySet 이름공간에 해당 메소드가 있는지 확인한 후 없다면 상위클래스인 list에서 찾게된다. 상위클래스인 list에서 해당 메소드가 존재하기때문에 별다른 메소드 정의 없이 해당 코드가 올바르게 수행된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [7번 문제] 프로젝트 오일러 문제 16\n",
    "2^1000의 각 자리수를 모두 더하면 얼마입니까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1366\n"
     ]
    }
   ],
   "source": [
    "x = str(2**1000)\n",
    "result = 0\n",
    "\n",
    "for i in x:\n",
    "    result += int(i)\n",
    "\n",
    "print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [8번 문제] 프로젝트 오일러 문제 17\n",
    "1부터 1,000까지 영어로 썼을 때는 모두 몇 개의 글자를 사용해야 할까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21124\n"
     ]
    }
   ],
   "source": [
    "# 규칙적인 수(1~9)와 비규칙적인 수(10의자리 수)들을 유지하는 사전 생성\n",
    "numdict = {'1':'one', '2':'two', '3':'three', '4':'four', '5':'five', '6':'six', '7':'seven', '8':'eight', '9':'nine', '10':'ten', \\\n",
    "    '11':'eleven', '12':'twelve', '13':'thirteen', '14':'fourteen', '15':'fifteen', '16':'sixteen', '17':'seventeen', '18':'eighteen', '19':'nineteen', '20':'twenty', \\\n",
    "    '30':'thirty', '40':'forty', '50':'fifty', '60':'sixty', '70':'seventy', '80':'eighty', '90':'ninety'}\n",
    "\n",
    "string = ''\n",
    "result = 0\n",
    "\n",
    "# string 변수에 숫자를 영문규칙으로 기술하여 저장\n",
    "for x in range(1, 1001):\n",
    "    tmp = str(x)\n",
    "    if x < 21:\n",
    "        string = numdict[tmp]        \n",
    "    elif len(tmp) == 2:           # 두자리 숫자일 경우\n",
    "        if tmp[1] == '0':\n",
    "            string = numdict[tmp]\n",
    "        else:\n",
    "            string = numdict[tmp[0] + '0'] + ' ' + numdict[tmp[1]]        \n",
    "    elif len(tmp) == 3:           # 세자리 숫자일 경우\n",
    "        if int(tmp[1:3]) < 21:\n",
    "            if tmp[1:3] == '00':\n",
    "                string = numdict[tmp[0]] + ' hundred'            \n",
    "            else:\n",
    "                string = numdict[tmp[0]] + ' hundred and ' + numdict[str(int(tmp[1:3]))]\n",
    "        elif int(tmp[1:3]) > 20:\n",
    "            if tmp[2] == '0':\n",
    "                string = numdict[tmp[0]] + ' hundred and ' + numdict[str(int(tmp[1:3]))]\n",
    "            else:\n",
    "                string = numdict[tmp[0]] + ' hundred and ' + numdict[tmp[1] + '0'] + ' ' + numdict[tmp[2]]\n",
    "    else:                         # 1,000일 경우\n",
    "        string = 'one thousand'\n",
    "    # 글자수를 유지하는 리스트로 매핑하여 리스트의 원소를 모두 더해 결과값에 더함\n",
    "    result += sum(map(len,string.split()))\n",
    "\n",
    "print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [9번 문제] 프로젝트 오일러 문제 18\n",
    "다음 삼각형에서 합이 최대가 되는 경로를 찾아서 그 합을 구하세요.\n",
    "![](https://github.com/hswoo911/Script_Programming/blob/master/triangle.PNG?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1074\n"
     ]
    }
   ],
   "source": [
    "import StringIO\n",
    "\n",
    "class node:\n",
    "    def __init__(self, v, i):\n",
    "        self.value = v\n",
    "        self.index = i    \n",
    "    left = None\n",
    "    right = None\n",
    "\n",
    "string = '''95 64\n",
    "17 47 82\n",
    "18 35 87 10\n",
    "20 04 82 47 65\n",
    "19 01 23 75 03 34\n",
    "88 02 77 73 07 63 67\n",
    "99 65 04 28 06 16 70 92\n",
    "41 41 26 56 83 40 80 70 33\n",
    "41 48 72 33 47 32 37 16 94 29\n",
    "53 71 44 65 25 43 91 52 97 51 14\n",
    "70 11 33 28 77 73 17 78 39 68 17 57\n",
    "91 71 52 38 17 14 91 43 58 50 27 29 48\n",
    "63 66 04 68 89 53 67 30 73 16 69 87 40 31\n",
    "04 62 98 27 23 09 70 98 73 93 38 53 60 04 23'''\n",
    "buf = StringIO.StringIO(string)\n",
    "\n",
    "nodeList = [node(75, 0)]                           \n",
    "index = 1\n",
    "for line in buf.readlines():                        \n",
    "    tmp = line.split()                              # nodeList에 이와같이 저장\n",
    "    for i in tmp:                                   #        (75,0)\n",
    "        nodeList.append(node(int(i),index))         #    (95,1)  (64,2)\n",
    "        index += 1                                  # (17,3) (47, 4) (82, 5)\n",
    "\n",
    "level = 1\n",
    "index = 0                                              \n",
    "while level != 15:                                  # 각 노드 연결   \n",
    "    for x in range(index, index + level):           #       0   \n",
    "        nodeList[x].left = nodeList[x + level]      #     /   \\\n",
    "        nodeList[x].right = nodeList[x + level + 1] #    1     2\n",
    "    index += level                                  #   / \\   / \\\n",
    "    level += 1                                      #  3  4  5  6\n",
    "\n",
    "result = 75\n",
    "index = 0\n",
    "\n",
    "# 3레벨씩 경로를 탐색하여 가장 그 합이 높은 경로를 구함\n",
    "while True:\n",
    "    llsum = nodeList[index].value + nodeList[index].left.value + nodeList[index].left.left.value\n",
    "    lrsum = nodeList[index].value + nodeList[index].left.value + nodeList[index].left.right.value\n",
    "    rlsum = nodeList[index].value + nodeList[index].right.value + nodeList[index].right.left.value\n",
    "    rrsum = nodeList[index].value + nodeList[index].right.value + nodeList[index].right.right.value\n",
    "    \n",
    "    maxsum = max(llsum, lrsum, rlsum, rrsum)\n",
    "    if maxsum == llsum:\n",
    "        result += nodeList[index].left.value\n",
    "        index = nodeList[index].left.index        \n",
    "    elif maxsum == lrsum:\n",
    "        result += nodeList[index].left.value\n",
    "        index = nodeList[index].left.index\n",
    "    elif maxsum == rlsum:\n",
    "        result += nodeList[index].right.value\n",
    "        index = nodeList[index].right.index\n",
    "    else:\n",
    "        result += nodeList[index].right.value\n",
    "        index = nodeList[index].right.index\n",
    "    \n",
    "    if nodeList[index].left.left == None:\n",
    "        if nodeList[index].value + nodeList[index].left.value >= nodeList[index].value + nodeList[index].right.value:\n",
    "            result += nodeList[index].left.value\n",
    "        else:\n",
    "            result += nodeList[index].right.value\n",
    "        break\n",
    "\n",
    "print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### [10번 문제]\n",
    "이전 Assignment 3 (Assignment 4가 아님)의 마지막 문제는 웹 URL로 지정된 웹페이지를 문자열로 가져와 모든 HTML 태그 및 CSS와 Javascript를 제외한 순수 텍스트를 얻어내고 그 안에 존재하는 단어를 추출하여 각 단어들에 대해 출현빈도를 사전형태({'world': 2, 'hello': 1, 'python': 1})로 저장하여 출력하는 것이었다. 이번에는 Assignment 3을 다시 확장/변형하여 다음과 같은 조건을 만족하도록 구현하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import string\n",
    "\n",
    "def WordsCount(url):\n",
    "    source = urllib2.urlopen(url).read()    \n",
    "    \n",
    "    # 소스로부터 단어 추출\n",
    "    words = []\n",
    "    start = end = 0     # start: 단어의 첫 위치를 가리킴 end: 단어의 끝+1을 가리킴\n",
    "    i = 0\n",
    "    while i < len(source):\n",
    "        if(source[i] == '>'):\n",
    "            start = i + 1\n",
    "        if(source[i] == '<'):\n",
    "            end = i\n",
    "            if(source[i-2:i+1] == '//<'):\n",
    "                while source[i:i+3] != '//]':\n",
    "                    i += 1\n",
    "                i += 2\n",
    "                start = i + 1\n",
    "            elif(source[i+1:i+6] == 'style'):\n",
    "                while source[i:i+8] != '</style>':\n",
    "                    i += 1\n",
    "                i += 7\n",
    "                start = i + 1\n",
    "            elif(source[i+1:i+7] == 'script'):\n",
    "                while source[i:i+9] != '</script>':\n",
    "                    i += 1\n",
    "                i += 8\n",
    "                start = i + 1\n",
    "            elif(source[i+1:i+4] == 'div'):\n",
    "                while source[i:i+4] != '/div':\n",
    "                    i += 1\n",
    "                i += 3\n",
    "                start = i + 1\n",
    "            elif(source[i+1:i+7] == 'iframe'):\n",
    "                while source[i:i+7] != '/iframe':\n",
    "                    i += 1\n",
    "                i += 6\n",
    "                start = i + 1\n",
    "            elif(source[i+1:i+9] == '!doctype' or source[i+1:i+9] == '!DOCTYPE'):\n",
    "                while source[i:i+4] != 'html':\n",
    "                    i += 1\n",
    "                i += 3\n",
    "                start = i + 1\n",
    "            elif(source[i+1] == '!'):            \n",
    "                while source[i:i+3] != '-->':\n",
    "                    i += 1\n",
    "                i += 2\n",
    "                start = i + 1\n",
    "            else:                                              # CSS가 아니라면\n",
    "                tmp = str(source[start:end]).strip().split()   # tmp 변수에 > 다음 문자부터 < 이전 문자까지\n",
    "                for x in range(len(tmp)):                      # 공백 제거 후 공백으로 분리\n",
    "                    words.append(tmp[x])                       # words 리스트에 단어 추가\n",
    "        i += 1\n",
    "\n",
    "    # 워드 리스트에서 특수문자 제거\n",
    "    i = 0\n",
    "    length = len(words)\n",
    "    while i < length:\n",
    "        words[i] = words[i].strip(string.punctuation)\n",
    "        if words[i] == '': \n",
    "            del(words[i])\n",
    "            length -= 1\n",
    "        else:\n",
    "            i += 1\n",
    "    \n",
    "    # 사전에 단어 추가 및 개수 증가\n",
    "    wDict = {}\n",
    "    for x in range(len(words)):\n",
    "        if words[x] not in wDict:\n",
    "            wDict[words[x]] = 1\n",
    "        else:\n",
    "            wDict[words[x]] += 1\n",
    "    \n",
    "    # 영어 불용어 제거\n",
    "    global stopWords\n",
    "    delStopWords(wDict, stopWords)\n",
    "    \n",
    "    return wDict # 결과사전 리턴\n",
    "\n",
    "def delStopWords(d, stopWords):\n",
    "    for x in d.keys():\n",
    "        if x in stopWords:\n",
    "            del(d[x])\n",
    "\n",
    "# 파일로부터 영어 불용어 리스트 생성\n",
    "f = open('stop_word_list.txt')\n",
    "stopWords = []\n",
    "for x in f.xreadlines():\n",
    "    if x != '' and x != '\\n':\n",
    "        stopWords.append(x.strip(' \\n'))\n",
    "        stopWords.append(x.strip(' \\n').title())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WebWordsFrequency:\n",
    "    def __init__(self, *urls):\n",
    "        self.urlList = []\n",
    "        for u in urls:            \n",
    "            self.urlList.append(u)\n",
    "\n",
    "    def addUrl(self, url):\n",
    "        self.urlList.append(url)\n",
    "\n",
    "    def removeUrl(self, url):\n",
    "        for i in range(len(self.urlList)):\n",
    "            if url == self.urlList[i]:\n",
    "                del(self.urlList[i])\n",
    "                break\n",
    "\n",
    "    def listUrls(self):\n",
    "        for i in self.urlList:\n",
    "            print i\n",
    "    \n",
    "    def getWordsFrequency(self):\n",
    "        resultDict = {}         # 사이트별 단어 사전을 종합한 사전\n",
    "        \n",
    "        wordsDict = []          # 사이트별 사전 리스트 [{1번 사이트 사전},{2번사이트 사전}...]\n",
    "        for url in self.urlList:\n",
    "            wordsDict.append(WordsCount(url))\n",
    "\n",
    "        i = 0\n",
    "        while i != len(wordsDict):\n",
    "            if len(wordsDict[i]) != 0:\n",
    "                tmp = wordsDict[i].popitem()     # i번째 사전에서 단어하나를 꺼냄\n",
    "                if tmp[0] in resultDict:         # 꺼낸 단어의 key값이 종합사전에 있다면\n",
    "                    resultDict[tmp[0]] += tmp[1] # 종합사전의 단어 빈도에 더해줌\n",
    "                else:                            # 종합사전에 존재하지 않는 단어인 경우\n",
    "                    resultDict[tmp[0]] = tmp[1]  # 단어와 빈도 추가\n",
    "            else:                                # 모든 단어를 꺼낸경우\n",
    "                i += 1                           # 다음 사전 검사를 위해 인덱스 증가\n",
    "        return resultDict\n",
    "    \n",
    "    def getMaxFreqencyWords(self):\n",
    "        from operator import itemgetter\n",
    "        tmp = []\n",
    "        resultList = []\n",
    "        compilDict = self.getWordsFrequency()\n",
    "\n",
    "        for key, value in sorted(compilDict.items(), key = itemgetter(1), reverse = True): # 빈도를 기준으로 내림차 정렬하여 원소를 하나씩 꺼냄\n",
    "            if len(tmp) == 0:                     # 임시 리스트가 비었다면 추가\n",
    "                tmp.append((key, value))\n",
    "            else:                                 # 최대값을 가진 튜플이 들어간 상태라면\n",
    "                if tmp[0][1] == value:            # 지금꺼낸 튜플의 value와 최대값 value와 비교\n",
    "                    tmp.append(key, value)        # 같으면 추가\n",
    "                else: \n",
    "                    break\n",
    "\n",
    "        for i in tmp:                 # 임시 리스트에서 key값만 복사\n",
    "            resultList.append(i[0])\n",
    "        \n",
    "        if len(resultList) > 0:\n",
    "            return resultList\n",
    "        else: return None\n",
    "\n",
    "    def searchUrlByWord(self, searchWord):\n",
    "        from operator import itemgetter\n",
    "\n",
    "        DictList = []          # 사이트별 사전 리스트 [(1번 url, {1번 사전}), .....]\n",
    "        for url in self.urlList:\n",
    "            DictList.append( (url, WordsCount(url)) )\n",
    "\n",
    "        similarity = {}\n",
    "\n",
    "        # 유사도 사전 초기화\n",
    "        for t in DictList:\n",
    "            similarity[t[0]] = 0\n",
    "\n",
    "        # 유사도 계산    \n",
    "        for t in DictList:\n",
    "            if searchWord in t[1]:\n",
    "                similarity[t[0]] = t[1][searchWord]\n",
    "\n",
    "        tmp = []\n",
    "\n",
    "        # 유사도 기준으로 정렬 후 출력\n",
    "        isover = False\n",
    "        for key, value in sorted(similarity.items(), key=itemgetter(1), reverse=True):\n",
    "            if len(tmp) == 0:\n",
    "                tmp.append((key, value))\n",
    "                print key\n",
    "            else:\n",
    "                if tmp[0][1] == value:             \n",
    "                    print key\n",
    "                else:                        \n",
    "                    break            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [11번 문제]\n",
    "\n",
    "위 10번 문제에서 정의한 WebWordsFrequency 클래스를 상속하여 OrderedWebWordsFrequency 클래스를 정의하고 슈퍼클래스에 정의된 getWordsFrequency() 메소드를 오버라이드 하여 단어 출현 빈도를 내림 차순으로 정렬하여 리스트로 출력하시오.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2016', 36), ('Global', 25), ('Thinkers', 24), ('ago', 18), ('Trump', 17), ('12', 15), ('Shares', 15), ('Dec', 12), ('Aired', 11), ('December', 11), ('recap', 10), ('Site', 10), ('1', 9), ('News', 9), ('Times', 8), ('FP', 8), ('Staff', 8), ('Style', 7), ('E.R', 7), ('days', 7), ('Sunday', 7), ('TV', 7), ('day', 6), ('11', 6), ('Navigation', 6), ('4', 6), ('Books', 6), ('hours', 5), ('Review', 5), ('Monday', 5), ('Magazine', 5), ('Trump\\xe2\\x80\\x99s', 5), ('Music', 5), ('Performers', 5), ('Rex', 4), ('0', 4), ('Time', 4), ('Video', 4), ('U.S', 4), ('Opinion', 4), ('Donald', 4), ('Tillerson', 4), ('ET', 4), ('EW', 4), ('York', 4), ('Education', 4), ('Secretary', 4), ('amp', 4), ('Life', 4), ('Business', 3), ('Home', 3), ('Health', 3), ('Dies', 3), ('Editorial', 3), ('Terms', 3), ('Texas', 3), ('World', 3), ('Choices', 3), ('Live', 3), ('Picks', 3), ('Photo', 3), ('Election', 3), ('Makes', 3), ('Women', 3), ('Exxon', 3), ('Night', 3), ('Service', 3), ('Privacy', 3), ('Holidays', 3), ('Approach', 3), ('Schools', 3), ('\\xe2\\x80\\x94', 3), ('Design', 3), ('Map', 3), ('Ideas', 3), ('10', 3), ('Leaf', 2), ('Department', 2), ('C.E.O', 2), ('Day', 2), ('Tech', 2), ('Voices', 2), ('Index', 2), ('Spending', 2), ('East', 2), ('Sections', 2), ('Subscriptions', 2), ('public', 2), ('Gift', 2), ('Age', 2), ('explore', 2), ('Contact', 2), ('Briefing', 2), ('nbsp;Comments', 2), ('Tuesday', 2), ('Top', 2), ('Europe', 2), ('Drugs', 2), ('Russian', 2), ('Rule', 2), ('Integration', 2), ('Policy', 2), ('Australian', 2), ('Shadow', 2), ('Industry', 2), ('Improve', 2), ('Who\\xe2\\x80\\x99s', 2), ('Middle', 2), ('Film', 2), ('Breaking', 2), ('Cable', 2), ('Fragile', 2), ('Era', 2), ('Help', 2), ('San', 2), ('Sport', 2), ('Arts', 2), ('Galleries', 2), ('Runs', 2), ('Sports', 2), ('health', 2), ('Stage', 2), ('Voyeur', 2), ('National', 2), ('Asia', 2), ('Probably', 2), ('Hopes', 2), ('Fits', 2), ('Recaps', 2), ('Movie', 2), ('It\\xe2\\x80\\x99s', 2), ('Food', 2), ('Meddling', 2), ('Rural', 2), ('raquo', 2), ('Saturday', 2), ('Role', 2), ('Favorite', 2), ('2', 2), ('Craig', 2), ('Funding', 2), ('John', 2), ('3', 2), ('Republican', 2), ('PM', 2), ('Advertise', 2), ('Astronauts,\\xe2\\x80\\x99', 2), ('Travel', 2), ('Holiday', 2), ('Mothers', 2), ('California', 2), ('Derailed', 2), ('Districts', 2), ('will.i.am', 2), ('Cold', 2), ('City', 2), ('Here\\xe2\\x80\\x99s', 2), ('Strategy', 2), ('vs', 2), ('Dead', 2), ('worry', 2), ('Obama\\xe2\\x80\\x99s', 2), ('Nation', 2), ('food', 2), ('President', 2), ('week', 2), ('Movies', 2), ('Dream', 2), ('Senate', 2), ('Tastes', 2), ('Entering', 2), ('Gaming', 2), ('Support', 2), ('Angry', 2), ('Reset', 2), ('Tea', 2), ('Weight-Loss', 2), ('world', 2), ('Heart', 2), ('Nominee', 2), ('Russia\\xe2\\x80\\x99s', 2), ('Learning', 2), ('Globe', 2), ('Britain\\xe2\\x80\\x99s', 2), ('5', 2), ('Fire', 2), ('holiday', 2), ('Leader', 2), ('Russia', 2), ('Information', 2), ('Martha', 2), ('Democracy', 2), ('Entertainment', 2), ('start', 2), ('Ashamed', 2), ('Detroit', 2), ('Golden', 2), ('Grapple', 2), ('Close', 2), ('Bathroom', 2), ('Real', 2), ('Begin', 2), ('Francisco', 2), ('Segregation', 2), ('Lab', 2), ('AM', 2), ('Trial', 2), ('Ad', 2), ('Am', 2), ('Friday', 1), ('coach', 1), ('exhibitions', 1), ('Lead', 1), ('Unknown', 1), ('Fix', 1), ('child', 1), ('Obamacare', 1), ('results', 1), ('Heights', 1), ('Betsy', 1), ('Soares', 1), ('protest', 1), ('Nadia', 1), ('EXCERPT', 1), ('Pride', 1), ('IABONI', 1), ('Evening', 1), ('Watch', 1), ('\\xe2\\x80\\x98Skam,\\xe2\\x80\\x99', 1), ('SINGHVI', 1), ('Iago', 1), ('Joint', 1), ('Intent', 1), ('rhythm', 1), ('Energy', 1), ('Atlanta', 1), ('Cappella', 1), ('THINKERS', 1), ('Pilgrim', 1), ('Celebrity', 1), ('Player\\xe2\\x80\\x99s', 1), ('Sale', 1), ('Medalist', 1), ('Artistic', 1), ('SAINT', 1), ('Restaurants', 1), ('Hitting', 1), ('school', 1), ('Parker', 1), ('Family', 1), ('exits', 1), ('experiencing', 1), ('Attia', 1), ('Hordes', 1), ('Tax', 1), ('Mogul', 1), ('Defense', 1), ('Blond', 1), ('succession', 1), ('Debate', 1), ('neighborhood', 1), ('leaders', 1), ('razed', 1), ('streets', 1), ('past', 1), ('video', 1), ('Heritage', 1), ('Bottomless', 1), ('depression', 1), ('Korea', 1), ('Calls', 1), ('declassified', 1), ('Rights', 1), ('shares', 1), ('Dissension', 1), ('Inside', 1), ('Abuse', 1), ('values', 1), ('Line', 1), ('Realized', 1), ('Presidential', 1), ('Ora', 1), ('mind-set', 1), ('led', 1), ('policies', 1), ('Brilliant', 1), ('Finance', 1), ('2:37', 1), ('Changes', 1), ('design', 1), ('America\\xe2\\x80\\x99s', 1), ('Founder', 1), ('precursor', 1), ('larger', 1), ('CATHERINE', 1), ('brutal', 1), ('President-Elect', 1), ('Resorts', 1), ('Legacy', 1), ('pick', 1), ('Inc', 1), ('makes', 1), ('Vulnerable', 1), ('diplomat', 1), ('criticism', 1), ('Finale', 1), ('deputy', 1), (\"It's\", 1), ('Multimedia', 1), ('treatment', 1), ('replace', 1), ('Book', 1), ('Meet', 1), ('Filmmaker', 1), ('Explains', 1), ('\\xe2\\x80\\x9cDesign', 1), ('Rita', 1), ('discuss', 1), ('Star', 1), ('Sold', 1), ('KAREN', 1), ('Betrayal', 1), ('Newsletter', 1), ('Driven', 1), ('live', 1), ('Cagle', 1), ('6', 1), ('Worst', 1), ('Recent', 1), ('abusing', 1), ('Smartphones', 1), ('Ben', 1), ('Christine', 1), ('LOUIS', 1), ('Laporte', 1), ('Feast', 1), ('Dependence', 1), ('Lagarde', 1), ('Merge', 1), ('Roger', 1), ('coyote', 1), ('Hacking', 1), ('95', 1), ('Generations', 1), ('women', 1), ('Affair', 1), ('Charter', 1), ('Feedback', 1), ('opioids', 1), ('Fillets', 1), ('Eat', 1), ('Lies', 1), ('Traveling', 1), ('taut', 1), ('Money', 1), ('Advertisers', 1), ('Nicola', 1), ('Tells', 1), ('Details', 1), ('Standing', 1), ('Oyelowo', 1), ('La', 1), ('Infographics', 1), ('Hudson', 1), ('Reality', 1), ('BUTTONS', 1), ('pushed', 1), ('Globalization', 1), ('Bruni', 1), ('ANJALI', 1), ('sense', 1), ('Party', 1), ('Sign', 1), ('Issue', 1), ('Christmas', 1), ('Norm', 1), ('Happened', 1), ('Latvia', 1), ('Tumblr', 1), ('Diaries', 1), ('Missing', 1), ('vibe', 1), ('Cause', 1), ('Paper', 1), ('1754', 1), ('III', 1), ('Mascolo', 1), ('Skewered', 1), ('plans', 1), ('List', 1), ('Disease', 1), ('FORD', 1), ('Americas', 1), ('Thank-You', 1), ('president', 1), ('Model', 1), ('law', 1), ('Corporate', 1), ('View', 1), ('Lodges', 1), ('Instagram', 1), ('Tunisian', 1), ('Sean', 1), ('Politics', 1), ('Sexual', 1), ('Andrew', 1), ('Cha', 1), ('BOEHLER', 1), ('interpretation', 1), ('10:50', 1), ('committed', 1), ('Biggest', 1), ('Tips', 1), ('Translate', 1), ('Decades', 1), ('24', 1), ('KATRIN', 1), ('Finish', 1), ('Hit', 1), ('21', 1), ('chosen', 1), (\"What's\", 1), ('Patz', 1), ('Popcast', 1), ('Cabinet', 1), ('production', 1), ('Opposition', 1), ('Judge', 1), ('weeks', 1), ('undermines', 1), ('Excites', 1), ('Secretarial', 1), ('EW.com', 1), ('Mercy', 1), ('Essay', 1), ('return', 1), ('Mobile', 1), ('Car', 1), ('Challenge', 1), ('Michael', 1), ('Hungry', 1), ('Question', 1), ('party', 1), ('schools', 1), ('Obesity', 1), ('Respond', 1), ('Infant', 1), ('pregnant', 1), ('Simple', 1), ('Friends', 1), ('Pro', 1), ('Deck', 1), ('attacks', 1), ('Deadline', 1), ('11907', 1), ('Gramer', 1), ('12302', 1), ('Braces', 1), ('Temples', 1), ('series', 1), ('Museum', 1), ('Joseph', 1), ('Dispatch', 1), ('Passport', 1), ('Bluetooth', 1), ('87', 1), ('Probe', 1), ('Discovery', 1), ('23877', 1), ('factors', 1), ('CEO', 1), ('Eyes', 1), ('increase', 1), ('Norwegian', 1), ('9:10', 1), ('7', 1), ('Overshadowing', 1), ('Report', 1), ('illustrate', 1), ('Housewives', 1), ('Town', 1), ('Theater', 1), ('Observation', 1), ('drifting', 1), ('withdrawal', 1), ('Button', 1), ('Stewart\\xe2\\x80\\x99s', 1), ('Stupid', 1), ('Security', 1), ('Foreign', 1), ('Severson', 1), ('care', 1), ('Walking', 1), ('Battery', 1), ('headphones', 1), ('times', 1), ('Celeb', 1), ('NASA', 1), ('Strongman', 1), ('Samba', 1), ('Walsh', 1), ('Effect', 1), ('Lists', 1), ('Goes', 1), ('Corruption', 1), ('Shakespeare\\xe2\\x80\\x99s', 1), ('976', 1), ('breathless', 1), ('North', 1), ('Nature', 1), ('Happily', 1), ('top', 1), ('system', 1), ('Tied', 1), ('regulation', 1), ('Notebook', 1), ('\\xe2\\x80\\x98Moonlight\\xe2\\x80\\x99', 1), (\"Weekly's\", 1), ('entrepreneur', 1), ('User', 1), ('Search', 1), ('Suspect\\xe2\\x80\\x99s', 1), ('\\xe2\\x80\\x98Days', 1), ('PATRICK', 1), ('wildly', 1), ('Administration&#8217;s', 1), ('Blogs', 1), ('Michelle', 1), ('Neediest', 1), ('Die', 1), ('Bookstores', 1), ('JASON', 1), ('copy', 1), ('Sept', 1), ('apologist', 1), ('Carpetbagger', 1), ('Reactions', 1), ('Gift-Giving', 1), ('Flawed', 1), ('19', 1), ('Portraits', 1), ('Italy\\xe2\\x80\\x99s', 1), ('Cyber', 1), ('Victor', 1), ('recording', 1), ('matter', 1), ('LISA', 1), ('Appetite', 1), ('Settlement', 1), ('newborns', 1), ('STEWART', 1), ('Carri\\xc3\\xb3n\\xe2\\x80\\x99s', 1), ('Oliver', 1), ('Court', 1), ('longs', 1), ('Peace', 1), ('Exception', 1), ('departure', 1), ('Regions', 1), ('Afrofuturism', 1), ('Writers', 1), ('1:03', 1), ('Designing', 1), ('Interview', 1), ('11486', 1), ('Soccer', 1), ('LaCrosse', 1), ('Beating', 1), ('Success', 1), ('Power', 1), ('there\\xe2\\x80\\x99s', 1), ('Price', 1), ('agency', 1), ('\\xe2\\x80\\x98La', 1), ('Sadiq', 1), ('Othello', 1), ('Kim', 1), ('season', 1), ('interior', 1), ('Albums', 1), ('Working-Class', 1), ('pain', 1), ('Robbie', 1), (\"Critic's\", 1), ('Optimism', 1), ('ZERNIKE', 1), ('react', 1), ('Caption', 1), ('73', 1), ('\\xe2\\x80\\x98In', 1), ('enduring', 1), ('Kanye', 1), ('Login', 1), ('gallery', 1), ('Comes', 1), ('Google', 1), ('Bent', 1), ('chronicle', 1), ('popularity', 1), ('disease', 1), ('Jean', 1), ('Botswana', 1), ('tech', 1), ('It&#039;s', 1), ('professional', 1), ('Speed', 1), ('Perfect', 1), ('09', 1), ('Rules', 1), ('centralized', 1), ('PrizeFighter', 1), ('bring', 1), ('Activist', 1), ('Paradise', 1), ('Forward', 1), ('Harrowing', 1), ('KATE', 1), ('Woman', 1), ('Captivating', 1), ('Rebels', 1), ('Entrepreneur', 1), ('Undo', 1), ('appreciated', 1), ('Hulu', 1), ('Moskin', 1), ('Channel', 1), ('Catch', 1), ('8', 1), ('Pool', 1), ('photographs', 1), ('Homes', 1), ('founding', 1), ('gains', 1), ('watching', 1), ('Notes', 1), ('13', 1), ('Reviews', 1), ('Pound', 1), ('reporters', 1), ('Quick', 1), ('Looms', 1), ('Leaders', 1), ('artist', 1), ('approach', 1), ('Peppercorns', 1), ('calling', 1), ('Channels', 1), ('Villain', 1), ('Harsh', 1), ('Well-Traveled', 1), ('BENNHOLD', 1), ('France', 1), ('Various', 1), ('portrait', 1), ('Voice', 1), ('Transit\\xe2\\x80\\x99', 1), ('youth', 1), ('Year\\xe2\\x80\\x99s', 1), ('Auto', 1), ('Rise', 1), ('repeal', 1), ('Choice', 1), ('House', 1), ('Prices', 1), ('Cage', 1), ('email', 1), ('Eternity', 1), ('Resting', 1), ('Timeless', 1), ('Watching', 1), ('Today\\xe2\\x80\\x99s', 1), ('Declassify', 1), ('southeast', 1), ('Advocates', 1), ('Subway', 1), ('Madonna', 1), ('rapidly', 1), ('Sang', 1), ('Gov&#039;t', 1), ('taking', 1), ('Hard', 1), ('according', 1), ('players', 1), ('Tours', 1), ('Syrian', 1), ('comes', 1), ('MELE', 1), ('Continues', 1), ('Lila', 1), ('Log', 1), ('1.5', 1), ('FESSENDEN', 1), ('DVD', 1), ('GLOBAL', 1), ('Hangover', 1), ('2nd', 1), ('62', 1), ('news', 1), ('252', 1), ('Borders', 1), ('War', 1), ('Movement', 1), ('Episode', 1), ('Torture', 1), ('Refugees', 1), ('Royals', 1), ('Gladys', 1), ('Chance', 1), ('Races', 1), ('Plan', 1), ('Pay', 1), ('anti-establishment', 1), ('Christopher', 1), ('Trouble', 1), ('Tokyo', 1), ('fire', 1), ('NIKITA', 1), ('dangerous', 1), ('Disastrous', 1), ('lives', 1), ('Defers', 1), ('Nominations', 1), ('Drops', 1), ('\\xe2\\x80\\x98Brexit\\xe2\\x80\\x99', 1), ('20', 1), ('Prevent', 1), ('troubled', 1), ('Inclusive', 1), ('Taste', 1), ('Persian', 1), ('Shameless', 1), ('Harrison', 1), ('free-market', 1), ('report', 1), ('Avenue', 1), ('Fish', 1), ('Concern', 1), ('Erased', 1), ('Basketball', 1), ('Khan', 1), ('Benedict', 1), ('Polaroids', 1), ('Literary', 1), ('experts', 1), ('Toxic', 1), ('We\\xe2\\x80\\x99re', 1), ('Schlaffer', 1), ('communal', 1), ('Cena', 1), ('Nigerian', 1), ('Anatomy\\xe2\\x80\\x9d', 1), ('apparently', 1), ('Vanderpump', 1), ('\\xe2\\x80\\x98Othello\\xe2\\x80\\x99', 1), ('Curator\\xe2\\x80\\x99s', 1), ('Safer', 1), ('Bernal', 1), ('difficult', 1), ('Won\\xe2\\x80\\x99t', 1), ('Monica', 1), ('premiere', 1), ('Ride', 1), ('overweight', 1), ('M.T.A', 1), ('DeVos', 1), ('hand', 1), ('Stunning', 1), ('Arianna', 1), ('Drug', 1), ('Woodward', 1), ('Worried', 1), ('recent', 1), ('kept', 1), ('\\xe2\\x80\\x99Do', 1), ('programs', 1), ('Julia', 1), ('Read', 1), ('Economic', 1), ('Mohamed', 1), ('Artists', 1), ('Redzepova', 1), ('Mobil', 1), ('Zambia', 1), ('researchers', 1), ('Living', 1), ('Truth', 1), ('Roma', 1), ('Crime', 1), ('Worries', 1), ('Daniel', 1), (\"We're\", 1), ('Flynn', 1), ('Gill', 1), ('Gleefully', 1), ('building\\xe2\\x80\\x99s', 1), ('Lives\\xe2\\x80\\x99', 1), ('Moguls', 1), ('Company', 1), ('Broken', 1), ('CHRISTOPHER', 1), ('save', 1), ('Arms', 1), ('Change', 1), ('Faster', 1), ('Performances', 1), ('WORKMAN', 1), ('C.I.A.\\xe2\\x80\\x99s', 1), (\"America's\", 1), ('Supreme', 1), ('Drake', 1), ('Tale', 1), ('cultural', 1), ('listening', 1), ('Harlem', 1), ('aide', 1), ('Talk', 1), ('Lofty', 1), ('Shop', 1), ('hosting', 1), ('Art', 1), ('West\\xe2\\x80\\x99s', 1), ('Passing', 1), ('G.O.P', 1), ('Cohen', 1), ('Newsletters', 1), ('Detroit\\xe2\\x80\\x99s', 1), ('Streaming', 1), ('i.am', 1), ('London', 1), ('Capture', 1), ('Californians', 1), ('Gulf', 1), ('people', 1), ('Share', 1), ('Brighten', 1), ('Yazidi', 1), ('Editor', 1), ('N.Y', 1), ('home', 1), (\"Tyra's\", 1), ('Diagrams', 1), ('lead', 1), ('Government', 1), ('Frank', 1), ('decision', 1), ('creative', 1), ('Kayla', 1), ('Montana', 1), ('Facebook', 1), ('Rubs', 1), ('ethos', 1), ('dilutes', 1), ('Murad', 1), ('Sight', 1), ('power', 1), ('Postcard', 1), ('Challengers', 1), ('Oklahoma', 1), ('Economics', 1), ('David', 1), ('Behavior', 1), ('Patriotic', 1), ('post', 1), ('Property', 1), ('Huffington', 1), ('counties', 1), ('Vampire', 1), ('Pamper', 1), ('Generation', 1), ('Cheap', 1), ('Argument', 1), ('Replace', 1), ('Impostors', 1), ('Americans', 1), ('Buick', 1), ('Fail', 1), ('Mayor', 1), ('Lovers', 1), ('Insider', 1), ('Helps', 1), ('Hearts', 1), ('Survive', 1), ('Week', 1), ('Selling', 1), ('ISIS', 1), ('jealousy', 1), ('Hillary', 1), ('Days', 1), ('raped', 1), ('HOROWITZ', 1), ('Times\\xe2\\x80\\x99s', 1), ('forward', 1), ('Obama', 1), ('Land,\\xe2\\x80\\x99', 1), ('Singer', 1), ('Science', 1), ('Spook', 1), ('Kitchen', 1), ('Rocks', 1), ('disproportionately', 1), ('Pigozzi', 1), ('Guide', 1), ('Geese', 1), ('Estate', 1), ('Gold', 1), ('Mediator', 1), ('Pistons', 1), ('Twitter', 1), ('Africa', 1), ('Esma', 1), ('Britain', 1), ('stories', 1), ('723', 1), ('abuses', 1), ('Care', 1), ('Odd', 1), ('Sturgeon', 1), ('Blow', 1), ('videos', 1), ('deaths', 1), ('Personal', 1), ('Concussion', 1), ('I.M.F', 1), ('influence', 1), ('Lake', 1), ('Hampshire', 1), ('21_21', 1), ('Hot', 1), ('chat', 1), ('International', 1), ('Innovators', 1), ('Elza', 1), ('Hurt', 1), ('Subscribe', 1), ('deadly', 1), ('Million', 1), ('Jobs', 1), ('Helping', 1), ('Five', 1), ('Interpreting', 1), ('Vibrant', 1), ('Sisters', 1), ('Law', 1), ('Philippines', 1), ('Customer', 1), ('elements', 1), ('Lost', 1), ('Netflix', 1), ('Edit', 1), ('N.F.L', 1), ('time', 1), ('Arnold', 1), ('Payments', 1), ('rural', 1), ('variable', 1), ('else', 1), ('Page', 1), ('South', 1), ('Stewart', 1), ('Uncompromising', 1), ('Consensus', 1), ('Jehiel', 1), ('Findings', 1), ('Charles', 1), ('Highlights', 1), ('Jess', 1), ('Scottish', 1), ('Nonfiction', 1), ('Village', 1), ('fresh', 1), ('Oakland', 1)]\n"
     ]
    }
   ],
   "source": [
    "class OrderedWebWordsFrequency(WebWordsFrequency):    \n",
    "    def getWordsFrequency(self, reverse = False):\n",
    "        from operator import itemgetter\n",
    "\n",
    "        resultDict = {}         # 사이트별 단어 사전을 종합한 사전\n",
    "        \n",
    "        wordsDict = []          # 사이트별 사전 리스트 [{1번 사이트 사전},{2번사이트 사전}...]\n",
    "        for url in self.urlList:\n",
    "            wordsDict.append(WordsCount(url))\n",
    "\n",
    "        i = 0\n",
    "        while i != len(wordsDict):\n",
    "            if len(wordsDict[i]) != 0:\n",
    "                tmp = wordsDict[i].popitem()     # i번째 사전에서 단어하나를 꺼냄\n",
    "                if tmp[0] in resultDict:         # 꺼낸 단어의 key값이 종합사전에 있다면\n",
    "                    resultDict[tmp[0]] += tmp[1] # 종합사전의 단어 빈도에 더해줌\n",
    "                else:                            # 종합사전에 존재하지 않는 단어인 경우\n",
    "                    resultDict[tmp[0]] = tmp[1]  # 단어와 빈도 추가\n",
    "            else:                                # 모든 단어를 꺼낸경우\n",
    "                i += 1                           # 다음 사전 검사를 위해 인덱스 증가        \n",
    "\n",
    "        if reverse == False:\n",
    "            result = []\n",
    "            for key, value in sorted(resultDict.items(), key = itemgetter(1), reverse = True):\n",
    "                result.append( (key, value) )\n",
    "            print result\n",
    "        elif reverse == True:\n",
    "            result = []\n",
    "            for key, value in sorted(resultDict.items(), key = itemgetter(1), reverse = False):\n",
    "                result.append( (key, value) )\n",
    "            print result\n",
    "\n",
    "w4 = OrderedWebWordsFrequency('http://www.nytimes.com/', 'http://foreignpolicy.com/', 'http://www.ew.com/')\n",
    "w4.getWordsFrequency()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [12번 문제]\n",
    "\n",
    "다음과 같은 코딩이 가능하도록 OrderedWebWordsFrequency 안에 반복자와 관련된 메소드를 추가하시오.\n",
    "\n",
    ">\\>\\> for i in w4:  \n",
    " \\>\\>\\> print i  \n",
    " ('site, 12)  \n",
    " ('science', 11)  \n",
    " ('hello', 8)  \n",
    " ('world', 2)  \n",
    " ('program', 1)  \n",
    " ('python', 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2016', 40)\n",
      "('Global', 25)\n",
      "('Thinkers', 24)\n",
      "('ago', 18)\n",
      "('Shares', 16)\n",
      "('Trump', 15)\n",
      "('1', 14)\n",
      "('12', 14)\n",
      "('Aired', 11)\n",
      "('Dec', 11)\n",
      "('December', 11)\n",
      "('recap', 10)\n",
      "('News', 10)\n",
      "('Site', 10)\n",
      "('Times', 8)\n",
      "('FP', 8)\n",
      "('York', 8)\n",
      "('Staff', 8)\n",
      "('Style', 7)\n",
      "('day', 7)\n",
      "('E.R', 7)\n",
      "('days', 7)\n",
      "('TV', 7)\n",
      "('Navigation', 6)\n",
      "('Sunday', 6)\n",
      "('Books', 6)\n",
      "('Rex', 5)\n",
      "('4', 5)\n",
      "('Opinion', 5)\n",
      "('Review', 5)\n",
      "('11', 5)\n",
      "('10', 5)\n",
      "('Trump\\xe2\\x80\\x99s', 5)\n",
      "('Performers', 5)\n",
      "('Golden', 5)\n",
      "('Time', 4)\n",
      "('Video', 4)\n",
      "('EW', 4)\n",
      "('Monday', 4)\n",
      "('Tillerson', 4)\n",
      "('ET', 4)\n",
      "('Education', 4)\n",
      "('Secretary', 4)\n",
      "('amp', 4)\n",
      "('Music', 4)\n",
      "('Globe', 4)\n",
      "('Life', 4)\n",
      "('AM', 4)\n",
      "('Business', 3)\n",
      "('Help', 3)\n",
      "('Health', 3)\n",
      "('0', 3)\n",
      "('Dies', 3)\n",
      "('Rule', 3)\n",
      "('Photo', 3)\n",
      "('Terms', 3)\n",
      "('Carpetbagger', 3)\n",
      "('Film', 3)\n",
      "('Texas', 3)\n",
      "('World', 3)\n",
      "('Choices', 3)\n",
      "('Live', 3)\n",
      "('Money', 3)\n",
      "('Donald', 3)\n",
      "('Magazine', 3)\n",
      "('Schools', 3)\n",
      "('Night', 3)\n",
      "('Ideas', 3)\n",
      "('President', 3)\n",
      "('Service', 3)\n",
      "('Privacy', 3)\n",
      "('Holidays', 3)\n",
      "('Nominee', 3)\n",
      "('Entertainment', 3)\n",
      "('It\\xe2\\x80\\x99s', 3)\n",
      "('Russia', 3)\n",
      "('\\xe2\\x80\\x94', 3)\n",
      "('Exxon', 3)\n",
      "('Map', 3)\n",
      "('Election', 3)\n",
      "('Leaf', 2)\n",
      "('Lead', 2)\n",
      "('Department', 2)\n",
      "('Tech', 2)\n",
      "('Voices', 2)\n",
      "('Index', 2)\n",
      "('Spending', 2)\n",
      "('\\xe2\\x80\\x98Moonlight\\xe2\\x80\\x99', 2)\n",
      "('Sections', 2)\n",
      "('Subscriptions', 2)\n",
      "('Gift', 2)\n",
      "('Age', 2)\n",
      "('hours', 2)\n",
      "('Contact', 2)\n",
      "('nbsp;Comments', 2)\n",
      "('Tuesday', 2)\n",
      "('Dead', 2)\n",
      "('Home', 2)\n",
      "('Top', 2)\n",
      "('diversion', 2)\n",
      "('Book', 2)\n",
      "('Meet', 2)\n",
      "('Europe', 2)\n",
      "('Share', 2)\n",
      "('Editorial', 2)\n",
      "('Day', 2)\n",
      "('Lies', 2)\n",
      "('La', 2)\n",
      "('Integration', 2)\n",
      "('Policy', 2)\n",
      "('U.S', 2)\n",
      "('Shadow', 2)\n",
      "('Industry', 2)\n",
      "('Improve', 2)\n",
      "('Who\\xe2\\x80\\x99s', 2)\n",
      "('Breaking', 2)\n",
      "('Mercy', 2)\n",
      "('Cable', 2)\n",
      "('Era', 2)\n",
      "('San', 2)\n",
      "('Arts', 2)\n",
      "('Galleries', 2)\n",
      "('Runs', 2)\n",
      "('Sports', 2)\n",
      "('7', 2)\n",
      "('Stage', 2)\n",
      "('Voyeur', 2)\n",
      "('National', 2)\n",
      "('Asia', 2)\n",
      "('Probably', 2)\n",
      "('Reset', 2)\n",
      "('Fits', 2)\n",
      "('Craig', 2)\n",
      "('Recaps', 2)\n",
      "('Movie', 2)\n",
      "('Power', 2)\n",
      "('Food', 2)\n",
      "('\\xe2\\x80\\x98La', 2)\n",
      "('Politics', 2)\n",
      "('Rural', 2)\n",
      "('2', 2)\n",
      "('raquo', 2)\n",
      "('Saturday', 2)\n",
      "('Reactions', 2)\n",
      "('Favorite', 2)\n",
      "('Funding', 2)\n",
      "('John', 2)\n",
      "('Choice', 2)\n",
      "('City', 2)\n",
      "('Makes', 2)\n",
      "('Advertise', 2)\n",
      "('Information', 2)\n",
      "('Travel', 2)\n",
      "('War', 2)\n",
      "('Chance', 2)\n",
      "('California', 2)\n",
      "('Women', 2)\n",
      "('Peace', 2)\n",
      "('Districts', 2)\n",
      "('Nominations', 2)\n",
      "('vs', 2)\n",
      "('Obama\\xe2\\x80\\x99s', 2)\n",
      "('Nation', 2)\n",
      "('\\xe2\\x80\\x98Othello\\xe2\\x80\\x99', 2)\n",
      "('week', 2)\n",
      "('Real', 2)\n",
      "('Movies', 2)\n",
      "('Entering', 2)\n",
      "('Artists', 2)\n",
      "('Price', 2)\n",
      "('Crime', 2)\n",
      "('Gaming', 2)\n",
      "('Company', 2)\n",
      "('Segregation', 2)\n",
      "('Angry', 2)\n",
      "('Tea', 2)\n",
      "('Weight-Loss', 2)\n",
      "('world', 2)\n",
      "('Learning', 2)\n",
      "('Chosen', 2)\n",
      "('Britain\\xe2\\x80\\x99s', 2)\n",
      "('5', 2)\n",
      "('Fire', 2)\n",
      "('Leader', 2)\n",
      "('David', 2)\n",
      "('Approach', 2)\n",
      "('Democracy', 2)\n",
      "('start', 2)\n",
      "('C.E.O', 2)\n",
      "('Land,\\xe2\\x80\\x99', 2)\n",
      "('Animals', 2)\n",
      "('Detroit', 2)\n",
      "('Grapple', 2)\n",
      "('Close', 2)\n",
      "('Bathroom', 2)\n",
      "('pretrial', 2)\n",
      "('Begin', 2)\n",
      "('Francisco', 2)\n",
      "('Lab', 2)\n",
      "('Ad', 2)\n",
      "('Oakland', 2)\n",
      "('coach', 1)\n",
      "('Surprises', 1)\n",
      "('Franken', 1)\n",
      "('results', 1)\n",
      "('Heights', 1)\n",
      "('Hitting', 1)\n",
      "('Soares', 1)\n",
      "('code', 1)\n",
      "('Nadia', 1)\n",
      "('EXCERPT', 1)\n",
      "('Pride', 1)\n",
      "('Memoir', 1)\n",
      "('increase', 1)\n",
      "('Guide', 1)\n",
      "('Voice', 1)\n",
      "('Seeking', 1)\n",
      "('\\xe2\\x80\\x98Skam,\\xe2\\x80\\x99', 1)\n",
      "('Filmmaker', 1)\n",
      "('Iago', 1)\n",
      "('Joint', 1)\n",
      "('Intent', 1)\n",
      "('Unknown', 1)\n",
      "('Atlanta', 1)\n",
      "('worth', 1)\n",
      "('resources', 1)\n",
      "('THINKERS', 1)\n",
      "('Pilgrim', 1)\n",
      "('Sanctions', 1)\n",
      "('Celebrity', 1)\n",
      "('Player\\xe2\\x80\\x99s', 1)\n",
      "('Sale', 1)\n",
      "('hosting', 1)\n",
      "('decide', 1)\n",
      "('Restaurants', 1)\n",
      "('Parker', 1)\n",
      "('Murad', 1)\n",
      "('1061', 1)\n",
      "('experiencing', 1)\n",
      "('Attia', 1)\n",
      "('Hordes', 1)\n",
      "('list', 1)\n",
      "('Mogul', 1)\n",
      "('Activist', 1)\n",
      "('Blond', 1)\n",
      "('Debate', 1)\n",
      "('Bracy', 1)\n",
      "('neighborhood', 1)\n",
      "('past', 1)\n",
      "('video', 1)\n",
      "('SEAN', 1)\n",
      "('Heritage', 1)\n",
      "('Bottomless', 1)\n",
      "('East', 1)\n",
      "('envisions', 1)\n",
      "('depression', 1)\n",
      "('Look', 1)\n",
      "('Korea', 1)\n",
      "('Rights', 1)\n",
      "('Dissension', 1)\n",
      "('Abuse', 1)\n",
      "('scientists', 1)\n",
      "('values', 1)\n",
      "('Line', 1)\n",
      "('America', 1)\n",
      "('Realized', 1)\n",
      "('public', 1)\n",
      "('exercise', 1)\n",
      "('TIERNEY', 1)\n",
      "('led', 1)\n",
      "('policies', 1)\n",
      "('Brilliant', 1)\n",
      "('explore', 1)\n",
      "('focused', 1)\n",
      "('Forgotten', 1)\n",
      "('Briefing', 1)\n",
      "('safer', 1)\n",
      "('Changes', 1)\n",
      "('3:27', 1)\n",
      "('Deal', 1)\n",
      "('precursor', 1)\n",
      "('5:00', 1)\n",
      "('larger', 1)\n",
      "('CATHERINE', 1)\n",
      "('Crown\\xe2\\x80\\x99', 1)\n",
      "('Resorts', 1)\n",
      "('Legacy', 1)\n",
      "('\\xe2\\x80\\x99s', 1)\n",
      "('makes', 1)\n",
      "('punishment', 1)\n",
      "('Vulnerable', 1)\n",
      "('Victor', 1)\n",
      "('Finale', 1)\n",
      "('useful', 1)\n",
      "('deputy', 1)\n",
      "(\"It's\", 1)\n",
      "('Multimedia', 1)\n",
      "('Passing', 1)\n",
      "('Rita', 1)\n",
      "('Star', 1)\n",
      "('Drugs', 1)\n",
      "('Sold', 1)\n",
      "('Betrayal', 1)\n",
      "('Ora', 1)\n",
      "('Newsletter', 1)\n",
      "('Lens', 1)\n",
      "('Fell', 1)\n",
      "('6', 1)\n",
      "('Russian', 1)\n",
      "('Worst', 1)\n",
      "('Recent', 1)\n",
      "('abusing', 1)\n",
      "('Smartphones', 1)\n",
      "('Ben', 1)\n",
      "('LOUIS', 1)\n",
      "('Laporte', 1)\n",
      "('Feast', 1)\n",
      "('Dependence', 1)\n",
      "('Americas', 1)\n",
      "('Merge', 1)\n",
      "('ALFANO', 1)\n",
      "('Roger', 1)\n",
      "('coyote', 1)\n",
      "('Reality', 1)\n",
      "('Generations', 1)\n",
      "('women', 1)\n",
      "('Housewives', 1)\n",
      "('Affair', 1)\n",
      "('Charter', 1)\n",
      "('Feedback', 1)\n",
      "('opioids', 1)\n",
      "('Fillets', 1)\n",
      "('disproportionately', 1)\n",
      "('Traveling', 1)\n",
      "('Globes', 1)\n",
      "('Advertisers', 1)\n",
      "('Nicola', 1)\n",
      "('President-Elect', 1)\n",
      "('Inc', 1)\n",
      "('Oyelowo', 1)\n",
      "('figure', 1)\n",
      "('process', 1)\n",
      "('favorite', 1)\n",
      "('DAVID', 1)\n",
      "('Blogs', 1)\n",
      "('Globalization', 1)\n",
      "('Bruni', 1)\n",
      "('Infographics', 1)\n",
      "('Party', 1)\n",
      "('times', 1)\n",
      "('Calif', 1)\n",
      "('Jarvis', 1)\n",
      "('Norm', 1)\n",
      "('Tumblr', 1)\n",
      "('Al', 1)\n",
      "('Diaries', 1)\n",
      "('Missing', 1)\n",
      "('vibe', 1)\n",
      "('Issue', 1)\n",
      "('low-risk', 1)\n",
      "('Paper', 1)\n",
      "('ensure', 1)\n",
      "('LEHREN', 1)\n",
      "('product', 1)\n",
      "('Mascolo', 1)\n",
      "('Skewered', 1)\n",
      "('intended', 1)\n",
      "('advice', 1)\n",
      "('List', 1)\n",
      "('Days', 1)\n",
      "('Model', 1)\n",
      "('View', 1)\n",
      "('Copts', 1)\n",
      "('Coffers', 1)\n",
      "('Lodges', 1)\n",
      "('Subscribe', 1)\n",
      "('effective', 1)\n",
      "('Instagram', 1)\n",
      "('Tunisian', 1)\n",
      "('Ala', 1)\n",
      "('Resist', 1)\n",
      "('Middle', 1)\n",
      "('Sean', 1)\n",
      "(\"Weekly's\", 1)\n",
      "('Kanye', 1)\n",
      "('Sexual', 1)\n",
      "('Andrew', 1)\n",
      "('Cha', 1)\n",
      "('interpretation', 1)\n",
      "('help', 1)\n",
      "('Vanderpump', 1)\n",
      "('Russia\\xe2\\x80\\x99s', 1)\n",
      "('Quick', 1)\n",
      "('Samba', 1)\n",
      "('including', 1)\n",
      "('Hearts', 1)\n",
      "('Tips', 1)\n",
      "('Translate', 1)\n",
      "('24', 1)\n",
      "('KATRIN', 1)\n",
      "('Hit', 1)\n",
      "('two-term', 1)\n",
      "('23', 1)\n",
      "('chosen', 1)\n",
      "(\"What's\", 1)\n",
      "('Continues', 1)\n",
      "('Cabinet', 1)\n",
      "('forms', 1)\n",
      "('unfunny', 1)\n",
      "('Judge', 1)\n",
      "('2017', 1)\n",
      "('criminal', 1)\n",
      "('decades', 1)\n",
      "('Excites', 1)\n",
      "('Secretarial', 1)\n",
      "('EW.com', 1)\n",
      "('MASLIN', 1)\n",
      "('Mobile', 1)\n",
      "('Car', 1)\n",
      "('Challenge', 1)\n",
      "('Fragile', 1)\n",
      "('Michael', 1)\n",
      "('Hungry', 1)\n",
      "('records', 1)\n",
      "('Sets', 1)\n",
      "('Worries', 1)\n",
      "('Obesity', 1)\n",
      "('Leaders', 1)\n",
      "('Supreme', 1)\n",
      "('pregnant', 1)\n",
      "('Simple', 1)\n",
      "('III', 1)\n",
      "('Pro', 1)\n",
      "('Gramer', 1)\n",
      "('Scottish', 1)\n",
      "('Multimedia/Photos', 1)\n",
      "('Sport', 1)\n",
      "('Braces', 1)\n",
      "('prompted', 1)\n",
      "('engaging', 1)\n",
      "('Joseph', 1)\n",
      "('Jobs', 1)\n",
      "('Passport', 1)\n",
      "('tough', 1)\n",
      "('event', 1)\n",
      "('Probe', 1)\n",
      "('Ross', 1)\n",
      "('Snubs', 1)\n",
      "('living', 1)\n",
      "('exacted', 1)\n",
      "('William', 1)\n",
      "('Norwegian', 1)\n",
      "('Widmer', 1)\n",
      "('Defense', 1)\n",
      "('health', 1)\n",
      "('Shakespeare\\xe2\\x80\\x99s', 1)\n",
      "('strategist', 1)\n",
      "('Town', 1)\n",
      "('Theater', 1)\n",
      "('Observation', 1)\n",
      "('Fills', 1)\n",
      "('withdrawal', 1)\n",
      "('Disease', 1)\n",
      "('Button', 1)\n",
      "('AARON', 1)\n",
      "('Stupid', 1)\n",
      "('vinyl', 1)\n",
      "('Security', 1)\n",
      "('Foreign', 1)\n",
      "('Finance', 1)\n",
      "('Walking', 1)\n",
      "('Battery', 1)\n",
      "('Nature', 1)\n",
      "('BYRD', 1)\n",
      "('Sign', 1)\n",
      "('Celeb', 1)\n",
      "('NASA', 1)\n",
      "('Egypt\\xe2\\x80\\x99s', 1)\n",
      "('industrial', 1)\n",
      "('man\\xe2\\x80\\x99s', 1)\n",
      "('Effect', 1)\n",
      "('email', 1)\n",
      "('Corruption', 1)\n",
      "('Exercise', 1)\n",
      "('Personality', 1)\n",
      "('city', 1)\n",
      "('breathless', 1)\n",
      "('North', 1)\n",
      "('Bargains', 1)\n",
      "('Mayor', 1)\n",
      "('Happily', 1)\n",
      "('top', 1)\n",
      "('system', 1)\n",
      "('Tied', 1)\n",
      "('Notebook', 1)\n",
      "('wildly', 1)\n",
      "('Hopes', 1)\n",
      "('JOHN', 1)\n",
      "('User', 1)\n",
      "('Search', 1)\n",
      "('Success', 1)\n",
      "('23885', 1)\n",
      "('\\xe2\\x80\\x98Days', 1)\n",
      "('season', 1)\n",
      "('Administration&#8217;s', 1)\n",
      "('Neediest', 1)\n",
      "('Bookstores', 1)\n",
      "('copy', 1)\n",
      "('apologist', 1)\n",
      "('Adults', 1)\n",
      "('13', 1)\n",
      "('Love', 1)\n",
      "('Flawed', 1)\n",
      "('Italy\\xe2\\x80\\x99s', 1)\n",
      "('Cyber', 1)\n",
      "('youth', 1)\n",
      "('matter', 1)\n",
      "('Diverse', 1)\n",
      "('Fake', 1)\n",
      "('274', 1)\n",
      "('Appetite', 1)\n",
      "('Settlement', 1)\n",
      "('steep', 1)\n",
      "('newborns', 1)\n",
      "('1.5', 1)\n",
      "('Oliver', 1)\n",
      "('Court', 1)\n",
      "('longs', 1)\n",
      "('Stake', 1)\n",
      "('Exception', 1)\n",
      "('Oklahoma', 1)\n",
      "('Regions', 1)\n",
      "('Afrofuturism', 1)\n",
      "('Writers', 1)\n",
      "('Designing', 1)\n",
      "('STREITFELD', 1)\n",
      "('6:44', 1)\n",
      "('Soccer', 1)\n",
      "('apparently', 1)\n",
      "('Kremlin', 1)\n",
      "('LaCrosse', 1)\n",
      "('gift-giving', 1)\n",
      "('Beating', 1)\n",
      "('Watching', 1)\n",
      "('there\\xe2\\x80\\x99s', 1)\n",
      "('Zambia', 1)\n",
      "('Eat', 1)\n",
      "('Meddling', 1)\n",
      "('Photos', 1)\n",
      "('subjects', 1)\n",
      "('Othello', 1)\n",
      "('C.I.A.\\xe2\\x80\\x99s', 1)\n",
      "('Albums', 1)\n",
      "('Dothan', 1)\n",
      "('Working-Class', 1)\n",
      "('pain', 1)\n",
      "('Robbie', 1)\n",
      "('price', 1)\n",
      "('reach', 1)\n",
      "('Optimism', 1)\n",
      "('react', 1)\n",
      "('Caption', 1)\n",
      "('73', 1)\n",
      "('Login', 1)\n",
      "('Comes', 1)\n",
      "('Rescue', 1)\n",
      "('Google', 1)\n",
      "('Bent', 1)\n",
      "('disease', 1)\n",
      "('Pop', 1)\n",
      "('Botswana', 1)\n",
      "('It&#039;s', 1)\n",
      "('Sturgeon', 1)\n",
      "('professional', 1)\n",
      "('Tall,\\xe2\\x80\\x99', 1)\n",
      "('1761', 1)\n",
      "('Tillerson\\xe2\\x80\\x99s', 1)\n",
      "('Perfect', 1)\n",
      "('09', 1)\n",
      "('Rules', 1)\n",
      "('PrizeFighter', 1)\n",
      "('spaces', 1)\n",
      "('Role', 1)\n",
      "('inconsistent', 1)\n",
      "('Paradise', 1)\n",
      "('Forward', 1)\n",
      "('Harrowing', 1)\n",
      "('Democratic', 1)\n",
      "('Captivating', 1)\n",
      "('Rebels', 1)\n",
      "('justice', 1)\n",
      "('CHARLES', 1)\n",
      "('3', 1)\n",
      "('Undo', 1)\n",
      "('appreciated', 1)\n",
      "('Hulu', 1)\n",
      "('Cagle', 1)\n",
      "('Channel', 1)\n",
      "('Catch', 1)\n",
      "('Entrepreneur', 1)\n",
      "('Pool', 1)\n",
      "('Homes', 1)\n",
      "('Colleges', 1)\n",
      "('Reviews', 1)\n",
      "('Stories', 1)\n",
      "('reporters', 1)\n",
      "('report', 1)\n",
      "('Defers', 1)\n",
      "('Temples', 1)\n",
      "('Deck', 1)\n",
      "('11933', 1)\n",
      "('Penalties', 1)\n",
      "('16', 1)\n",
      "('Peppercorns', 1)\n",
      "('calling', 1)\n",
      "('Channels', 1)\n",
      "('Villain', 1)\n",
      "('Presidential', 1)\n",
      "('Portraits', 1)\n",
      "('NIR', 1)\n",
      "('\\xe2\\x80\\x98Stand', 1)\n",
      "('Harsh', 1)\n",
      "('Hurt', 1)\n",
      "('Well-Traveled', 1)\n",
      "('BENNHOLD', 1)\n",
      "('Popcast', 1)\n",
      "('Spread', 1)\n",
      "('White', 1)\n",
      "('Year\\xe2\\x80\\x99s', 1)\n",
      "('Auto', 1)\n",
      "('Tool', 1)\n",
      "('Rise', 1)\n",
      "('Qualify', 1)\n",
      "('future', 1)\n",
      "('House', 1)\n",
      "('Prices', 1)\n",
      "('Republican', 1)\n",
      "('Cage', 1)\n",
      "('No-Exit', 1)\n",
      "('Kitchen', 1)\n",
      "('Eternity', 1)\n",
      "('vows', 1)\n",
      "('Timeless', 1)\n",
      "('Today\\xe2\\x80\\x99s', 1)\n",
      "('Telling', 1)\n",
      "('southeast', 1)\n",
      "('Propaganda\\xe2\\x80\\x94From', 1)\n",
      "('Advocates', 1)\n",
      "('Cause', 1)\n",
      "('rapidly', 1)\n",
      "('satirizing', 1)\n",
      "('Friends', 1)\n",
      "('Walsh', 1)\n",
      "('weeks', 1)\n",
      "('Partying', 1)\n",
      "('Astronauts,\\xe2\\x80\\x99', 1)\n",
      "('Sang', 1)\n",
      "('Fish', 1)\n",
      "('Hard', 1)\n",
      "('according', 1)\n",
      "('Laura', 1)\n",
      "('players', 1)\n",
      "('Tours', 1)\n",
      "('senator', 1)\n",
      "('Syrian', 1)\n",
      "('Mohamed', 1)\n",
      "('Readers', 1)\n",
      "('Friday', 1)\n",
      "('Lila', 1)\n",
      "('Log', 1)\n",
      "('simple', 1)\n",
      "('DVD', 1)\n",
      "('GLOBAL', 1)\n",
      "('Hangover', 1)\n",
      "('62', 1)\n",
      "('SHAILA', 1)\n",
      "('news', 1)\n",
      "('bizarre', 1)\n",
      "('it\\xe2\\x80\\x99s', 1)\n",
      "('Movement', 1)\n",
      "('Sisi', 1)\n",
      "('Episode', 1)\n",
      "('Beauty', 1)\n",
      "('cares', 1)\n",
      "('Refugees', 1)\n",
      "('Royals', 1)\n",
      "('Disastrous', 1)\n",
      "('Plan', 1)\n",
      "('Pay', 1)\n",
      "('Trouble', 1)\n",
      "('Gen', 1)\n",
      "('1034', 1)\n",
      "('Founder', 1)\n",
      "('Derailed', 1)\n",
      "('Mothers', 1)\n",
      "('fire', 1)\n",
      "('Vibrant', 1)\n",
      "('priced', 1)\n",
      "('Credit', 1)\n",
      "('lives', 1)\n",
      "('prices', 1)\n",
      "('Drops', 1)\n",
      "('SAINT', 1)\n",
      "('\\xe2\\x80\\x98Brexit\\xe2\\x80\\x99', 1)\n",
      "('Prevent', 1)\n",
      "('Medalist', 1)\n",
      "('look', 1)\n",
      "('Inclusive', 1)\n",
      "('will.i.am', 1)\n",
      "('Billions', 1)\n",
      "('Culture', 1)\n",
      "('Persian', 1)\n",
      "('Shameless', 1)\n",
      "('Harrison', 1)\n",
      "('Cold', 1)\n",
      "('Energy', 1)\n",
      "('Concern', 1)\n",
      "('Woman', 1)\n",
      "('Basketball', 1)\n",
      "('Khan', 1)\n",
      "('Benedict', 1)\n",
      "('SAMANTHA', 1)\n",
      "('Strategy', 1)\n",
      "('Literary', 1)\n",
      "('Interview', 1)\n",
      "('Here\\xe2\\x80\\x99s', 1)\n",
      "('11486', 1)\n",
      "('Toxic', 1)\n",
      "('return', 1)\n",
      "('We\\xe2\\x80\\x99re', 1)\n",
      "('Outsiders', 1)\n",
      "('Schlaffer', 1)\n",
      "('communal', 1)\n",
      "('Cena', 1)\n",
      "('Nigerian', 1)\n",
      "('Vampire', 1)\n",
      "('Stop', 1)\n",
      "('Boxer\\xe2\\x80\\x99s', 1)\n",
      "('Challengers', 1)\n",
      "('Die', 1)\n",
      "('party', 1)\n",
      "('Safer', 1)\n",
      "('Resting', 1)\n",
      "('Bernal', 1)\n",
      "('difficult', 1)\n",
      "('Won\\xe2\\x80\\x99t', 1)\n",
      "('Monica', 1)\n",
      "('premiere', 1)\n",
      "('overweight', 1)\n",
      "('diplomat', 1)\n",
      "('Stunning', 1)\n",
      "('Arianna', 1)\n",
      "('Drug', 1)\n",
      "('Woodward', 1)\n",
      "('Worried', 1)\n",
      "('Dream', 1)\n",
      "('kept', 1)\n",
      "('\\xe2\\x80\\x99Do', 1)\n",
      "('Senate', 1)\n",
      "('Latvia', 1)\n",
      "('Read', 1)\n",
      "('Tastes', 1)\n",
      "('Economic', 1)\n",
      "('grip', 1)\n",
      "('Redzepova', 1)\n",
      "('researchers', 1)\n",
      "('Living', 1)\n",
      "('Essay', 1)\n",
      "('Roma', 1)\n",
      "('Editors', 1)\n",
      "('Daniel', 1)\n",
      "(\"We're\", 1)\n",
      "('Internet', 1)\n",
      "('Khadijah', 1)\n",
      "('Flynn', 1)\n",
      "('Gill', 1)\n",
      "('Gleefully', 1)\n",
      "('Lives\\xe2\\x80\\x99', 1)\n",
      "('Moguls', 1)\n",
      "('Mattis\\xe2\\x80\\x99s', 1)\n",
      "('Broken', 1)\n",
      "('Sadiq', 1)\n",
      "('Christopher', 1)\n",
      "('prison', 1)\n",
      "('Support', 1)\n",
      "('Change', 1)\n",
      "('SARAH', 1)\n",
      "('Faster', 1)\n",
      "('Performances', 1)\n",
      "(\"America's\", 1)\n",
      "('Infant', 1)\n",
      "('Drake', 1)\n",
      "('Tale', 1)\n",
      "('Linney', 1)\n",
      "('Truth', 1)\n",
      "('Harlem', 1)\n",
      "('aide', 1)\n",
      "('Talk', 1)\n",
      "('Lofty', 1)\n",
      "('Shop', 1)\n",
      "('Heart', 1)\n",
      "('Fashion', 1)\n",
      "('West\\xe2\\x80\\x99s', 1)\n",
      "('Cohen', 1)\n",
      "('Newsletters', 1)\n",
      "('journalism', 1)\n",
      "('Streaming', 1)\n",
      "('London', 1)\n",
      "('offenders', 1)\n",
      "('Capture', 1)\n",
      "('Californians', 1)\n",
      "('Gulf', 1)\n",
      "('Influence', 1)\n",
      "('Online', 1)\n",
      "('Brighten', 1)\n",
      "('Yazidi', 1)\n",
      "('111', 1)\n",
      "('Editor', 1)\n",
      "('N.Y', 1)\n",
      "('12428', 1)\n",
      "('home', 1)\n",
      "(\"Tyra's\", 1)\n",
      "('Borders', 1)\n",
      "('Prosecutor', 1)\n",
      "('Holiday', 1)\n",
      "('describing', 1)\n",
      "('ANDREW', 1)\n",
      "('Government', 1)\n",
      "('Frank', 1)\n",
      "('decision', 1)\n",
      "('\\xe2\\x80\\x9cdiscounts,\\xe2\\x80\\x9d', 1)\n",
      "('Kayla', 1)\n",
      "('Montana', 1)\n",
      "('Facebook', 1)\n",
      "('Rubs', 1)\n",
      "('3:30', 1)\n",
      "(\"Critic's\", 1)\n",
      "('holiday', 1)\n",
      "('Polaroids', 1)\n",
      "('Calls', 1)\n",
      "('Postcard', 1)\n",
      "('Journalism', 1)\n",
      "('DUHIGG', 1)\n",
      "('Economics', 1)\n",
      "('deadly', 1)\n",
      "('Arnold', 1)\n",
      "('post', 1)\n",
      "('Property', 1)\n",
      "('Huffington', 1)\n",
      "('counties', 1)\n",
      "('Pamper', 1)\n",
      "('Generation', 1)\n",
      "('Cheap', 1)\n",
      "('Argument', 1)\n",
      "('Replace', 1)\n",
      "('Impostors', 1)\n",
      "('Americans', 1)\n",
      "('Solutions', 1)\n",
      "('Buick', 1)\n",
      "('Slate', 1)\n",
      "('Lovers', 1)\n",
      "('Social', 1)\n",
      "('Insider', 1)\n",
      "('Helps', 1)\n",
      "('artists', 1)\n",
      "('Survive', 1)\n",
      "('Martha', 1)\n",
      "('Week', 1)\n",
      "('Driven', 1)\n",
      "('Selling', 1)\n",
      "('Brooklyn', 1)\n",
      "('Lists', 1)\n",
      "('raped', 1)\n",
      "('Times\\xe2\\x80\\x99s', 1)\n",
      "('Characters', 1)\n",
      "('forward', 1)\n",
      "('Singer', 1)\n",
      "('Science', 1)\n",
      "('Rocks', 1)\n",
      "('Jean', 1)\n",
      "('Pigozzi', 1)\n",
      "('Leonhardt', 1)\n",
      "('\\xe2\\x80\\x98The', 1)\n",
      "('Geese', 1)\n",
      "('Estate', 1)\n",
      "('Gold', 1)\n",
      "('Mediator', 1)\n",
      "('Pistons', 1)\n",
      "('Twitter', 1)\n",
      "('Africa', 1)\n",
      "('Esma', 1)\n",
      "('Britain', 1)\n",
      "('Vow', 1)\n",
      "('stories', 1)\n",
      "('723', 1)\n",
      "('Care', 1)\n",
      "('Gov&#039;t', 1)\n",
      "('called', 1)\n",
      "('election', 1)\n",
      "('dangerous', 1)\n",
      "('videos', 1)\n",
      "('classic', 1)\n",
      "('Personal', 1)\n",
      "('Concussion', 1)\n",
      "('Hudson', 1)\n",
      "('Jealousy', 1)\n",
      "('Lake', 1)\n",
      "('Hampshire', 1)\n",
      "('Hot', 1)\n",
      "('International', 1)\n",
      "('Innovators', 1)\n",
      "('Elza', 1)\n",
      "('Op-Ed', 1)\n",
      "('DEWAN', 1)\n",
      "('Jess', 1)\n",
      "('fixing', 1)\n",
      "('Million', 1)\n",
      "('treatment', 1)\n",
      "('87', 1)\n",
      "('Helping', 1)\n",
      "('politicians', 1)\n",
      "('Five', 1)\n",
      "('Interpreting', 1)\n",
      "('warehouse', 1)\n",
      "('Customer', 1)\n",
      "('Lost', 1)\n",
      "('Netflix', 1)\n",
      "('Edit', 1)\n",
      "('N.F.L', 1)\n",
      "('STARK', 1)\n",
      "('Payments', 1)\n",
      "('rural', 1)\n",
      "('variable', 1)\n",
      "('highlighting', 1)\n",
      "('else', 1)\n",
      "('Page', 1)\n",
      "('South', 1)\n",
      "('Stewart', 1)\n",
      "('Uncompromising', 1)\n",
      "('Jehiel', 1)\n",
      "('Findings', 1)\n",
      "('wife', 1)\n",
      "('Mission', 1)\n",
      "('Highlights', 1)\n",
      "('Brain', 1)\n",
      "('Nonfiction', 1)\n",
      "('Village', 1)\n",
      "('Contributor', 1)\n",
      "('fresh', 1)\n"
     ]
    }
   ],
   "source": [
    "class OrderedWebWordsFrequency(WebWordsFrequency):\n",
    "    def __init__(self, *urls):\n",
    "        self.result = []\n",
    "        self.urlList = []\n",
    "        for u in urls:            \n",
    "            self.urlList.append(u)\n",
    "\n",
    "    def __getitem__(self, n):\n",
    "        return self.result[n]\n",
    "        \n",
    "        \n",
    "    def getWordsFrequency(self, reverse = False):        \n",
    "        from operator import itemgetter\n",
    "\n",
    "        resultDict = {}         # 사이트별 단어 사전을 종합한 사전\n",
    "        \n",
    "        wordsDict = []          # 사이트별 사전 리스트 [{1번 사이트 사전},{2번사이트 사전}...]\n",
    "        for url in self.urlList:\n",
    "            wordsDict.append(WordsCount(url))\n",
    "\n",
    "        i = 0\n",
    "        while i != len(wordsDict):\n",
    "            if len(wordsDict[i]) != 0:\n",
    "                tmp = wordsDict[i].popitem()     # i번째 사전에서 단어하나를 꺼냄\n",
    "                if tmp[0] in resultDict:         # 꺼낸 단어의 key값이 종합사전에 있다면\n",
    "                    resultDict[tmp[0]] += tmp[1] # 종합사전의 단어 빈도에 더해줌\n",
    "                else:                            # 종합사전에 존재하지 않는 단어인 경우\n",
    "                    resultDict[tmp[0]] = tmp[1]  # 단어와 빈도 추가\n",
    "            else:                                # 모든 단어를 꺼낸경우\n",
    "                i += 1                           # 다음 사전 검사를 위해 인덱스 증가        \n",
    "\n",
    "        if reverse == False:\n",
    "            self.result = []\n",
    "            for key, value in sorted(resultDict.items(), key = itemgetter(1), reverse = True):\n",
    "                self.result.append( (key, value) )\n",
    "            return self.result\n",
    "        elif reverse == True:\n",
    "            self.result = []\n",
    "            for key, value in sorted(resultDict.items(), key = itemgetter(1), reverse = False):\n",
    "                self.result.append( (key, value) )\n",
    "            return self.result\n",
    "\n",
    "w4 = OrderedWebWordsFrequency('http://www.nytimes.com/', 'http://foreignpolicy.com/', 'http://www.ew.com/')\n",
    "w4.getWordsFrequency()\n",
    "for i in w4:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 소감"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "한 학기 동안 파이썬을 배우면서 정말 간단하면서도 강력한 언어라고 느껴졌습니다. 앞으로 주력 언어로 개발하기 전단계에 사용할 수 있는 서브언어로 사용할 수 있을 정도로 좀 더 활용해 봐야겠다는 생각이 들었습니다."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
